import streamlit as st
import tensorflow as tf
import cv2
import numpy as np
from PIL import Image
from streamlit_drawable_canvas import st_canvas

# 1. é é¢è¨­å®š
st.set_page_config(page_title="AIæ‰‹å¯«è¾¨è­˜APP", layout="wide")

# åˆå§‹åŒ–çµ±è¨ˆæ•¸æ“š (Session State)
if 'total_count' not in st.session_state:
    st.session_state.total_count = 0
if 'correct_count' not in st.session_state:
    st.session_state.correct_count = 0

# --- CSS è£œå¼· (é˜²æ­¢è¡Œå‹•ç«¯ä¸‹æ‹‰åˆ·æ–°) ---
st.markdown(
    """
    <style>
    html, body, [data-testid="stAppViewContainer"] {
        overscroll-behavior-y: contain !important;
        overflow: hidden !important;
    }
    canvas { touch-action: none !important; }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ”¢ AIæ‰‹å¯«è¾¨è­˜APP")
st.markdown("""
##### ğŸ’¡ **ä½¿ç”¨èªªæ˜ï¼š**
1. **å¤šå…ƒè¼¸å…¥æ¨¡å¼**ï¼šæ”¯æ´ç•«æ¿æ‰‹å¯«ã€æ‹ç…§ã€åœ–ç‰‡æª”æ¡ˆä¸Šå‚³ã€‚
2. **æœ€ä½³è¾¨è­˜å»ºè­°**ï¼šå»ºè­°ä½¿ç”¨è¼ƒç²—çš„ç­†æ›¸å¯«ï¼Œä¸¦åœ¨å…‰æºå……è¶³çš„æƒ…æ³ä¸‹æ‹æ”ã€‚
3. **æ€§èƒ½å„ªåŒ–æ‰‹è…•**ï¼šè‹¥è¾¨è­˜ä¸ä½³ï¼Œå¯ä½¿ç”¨å´é¢æ¿å¾®èª¿åƒæ•¸ã€‚
4. **æ‰‹å¯«æ³¨æ„äº‹é …**ï¼šæ‰‹å¯«éƒ¨åˆ†å‹¿å¤ªé è¿‘é‚Šæ¡†ï¼Œä»¥å…è¾¨è­˜éŒ¯èª¤ã€‚
""")
st.divider()

# 2. è¼‰å…¥æ¨¡å‹
@st.cache_resource
def load_my_model():
    return tf.keras.models.load_model('mnist_model.h5')

try:
    model = load_my_model()
    st.sidebar.success("âœ… AI æ¨¡å‹å·²å°±ç·’")
except Exception as e:
    st.sidebar.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—")

# 3. å´é‚Šæ¬„
st.sidebar.header("ğŸ› ï¸ ç³»çµ±åŠŸèƒ½è¨­å®š")
option = st.sidebar.radio("ğŸ“¸ é¸æ“‡è¼¸å…¥ä¾†æºï¼š", ("æ‰‹å¯«ç•«æ¿æ¨¡å¼", "ä½¿ç”¨ç›¸æ©Ÿæ‹ç…§", "ä¸Šå‚³åœ–ç‰‡æª”"))

# æ­·å²çµ±è¨ˆé¡¯ç¤º
st.sidebar.divider()
st.sidebar.subheader("ğŸ“Š æ­·å²è¾¨è­˜çµ±è¨ˆ")
if st.session_state.total_count > 0:
    acc = (st.session_state.correct_count / st.session_state.total_count) * 100
    st.sidebar.write(f"ç¸½è¾¨è­˜æ¬¡æ•¸: {st.session_state.total_count}")
    st.sidebar.write(f"æ­£ç¢ºæ¬¡æ•¸: {st.session_state.correct_count}")
    st.sidebar.metric("æ­·å²æ­£ç¢ºç‡", f"{acc:.2f}%")
    if st.sidebar.button("ğŸ—‘ï¸ åˆªé™¤çµ±è¨ˆç´€éŒ„"):
        st.session_state.total_count = 0
        st.session_state.correct_count = 0
        st.rerun()
else:
    st.sidebar.write("å°šç„¡çµ±è¨ˆè³‡æ–™")

st.sidebar.divider()
st.sidebar.write("ğŸ” è¾¨è­˜åƒæ•¸å¾®èª¿ (æ‹ç…§/ä¸Šå‚³å°ˆç”¨)")
min_area = st.sidebar.slider("1. é›œè¨Šéæ¿¾å¼·åº¦", 100, 1500, 300)
sensitivity = st.sidebar.slider("2. æ•æ‰éˆæ•åº¦", 1, 25, 12)
thickness = st.sidebar.slider("3. å­—é«”åŠ ç²—ç¨‹åº¦", 1, 5, 2)

# 4. å½±åƒè™•ç†å‡½æ•¸ (åŒ…å« Padding å„ªåŒ–)
def process_and_predict(img_gray, is_canvas=False):
    if is_canvas:
        _, thresh = cv2.threshold(img_gray, 1, 255, cv2.THRESH_BINARY)
    else:
        enhanced = cv2.convertScaleAbs(img_gray, alpha=1.5, beta=0)
        blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)
        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                       cv2.THRESH_BINARY_INV, 11, sensitivity)
        kernel = np.ones((3,3), np.uint8)
        thresh = cv2.dilate(thresh, kernel, iterations=thickness)

    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    valid_contours = sorted([c for c in contours if cv2.contourArea(c) > min_area], 
                            key=lambda c: cv2.boundingRect(c)[0])
    
    if not valid_contours:
        return None, None, None

    results, confidences, roi_images = [], [], []
    for cnt in valid_contours:
        x, y, w, h = cv2.boundingRect(cnt)
        roi = thresh[y:y+h, x:x+w]
        
        # åŠ å¤§ Padding ç¢ºä¿ 1 ä¸æœƒè®Šå½¢
        pad = 30
        digit_canvas = cv2.copyMakeBorder(roi, pad, pad, pad, pad, cv2.BORDER_CONSTANT, value=0)
        final_img = cv2.resize(digit_canvas, (28, 28), interpolation=cv2.INTER_AREA)
        
        input_data = final_img.astype('float32') / 255.0
        input_data = np.expand_dims(input_data, axis=(0, -1))
        prediction = model.predict(input_data, verbose=0)
        
        results.append(np.argmax(prediction))
        confidences.append(np.max(prediction))
        roi_images.append(final_img)
        
    return results, confidences, roi_images

# 5. æ¨¡å¼åˆ‡æ›é‚è¼¯
if option == "æ‰‹å¯«ç•«æ¿æ¨¡å¼":
    st.write("### âœï¸ è«‹åœ¨é»‘è‰²ç•«æ¿å…§å¯«å…¥æ•¸å­—ï¼š")
    
    # ç§»é™¤æ©¡çš®æ“¦åˆ‡æ›ï¼Œå›æ­¸å–®ä¸€ç©©å®šç•«æ¿
    canvas_result = st_canvas(
        fill_color="rgba(255, 255, 255, 0.3)",
        stroke_width=15,
        stroke_color="#FFFFFF",
        background_color="#000000",
        width=700, height=500,
        drawing_mode="freedraw",
        key="canvas_fixed",
    )
    
    if canvas_result.image_data is not None:
        if st.button("ğŸš€ é€²è¡Œ AI è¾¨è­˜"):
            img_raw = canvas_result.image_data.astype('uint8')
            img_gray = cv2.cvtColor(img_raw, cv2.COLOR_RGBA2GRAY)
            res, confs, imgs = process_and_predict(img_gray, is_canvas=True)
            if res:
                final_str = ''.join(map(str, res))
                st.session_state['last_res'] = final_str # æš«å­˜çµæœçµ¦å›é¥‹å€ç”¨
                st.success(f"## æœ€çµ‚è¾¨è­˜çµæœï¼š {final_str}")
                
                cols = st.columns(len(imgs))
                for i, im in enumerate(imgs):
                    with cols[i]:
                        st.image(im, caption=f"é æ¸¬: {res[i]} ({confs[i]*100:.1f}%)")
            else:
                st.warning("è«‹åœ¨ç•«æ¿ä¸Šæ›¸å¯«æ•¸å­—ã€‚")

    # --- ä¿®æ­£å¾Œçš„å ±éŒ¯å›é¥‹å€ (æ”¾åœ¨è¾¨è­˜æŒ‰éˆ•å¤–ï¼Œç¢ºä¿åæ‡‰éˆæ•) ---
    if 'last_res' in st.session_state:
        st.divider()
        st.subheader("ğŸš© è¾¨è­˜å›é¥‹èˆ‡çµ±è¨ˆ")
        col_input, col_btn = st.columns([3, 1])
        with col_input:
            user_val = st.text_input("å¦‚æœè¾¨è­˜éŒ¯èª¤ï¼Œè«‹åœ¨æ­¤è¼¸å…¥æ­£ç¢ºæ•¸å€¼ï¼š", value=st.session_state['last_res'])
        with col_btn:
            st.write(" ") # å°é½Šç”¨
            if st.button("æäº¤å›é¥‹ç´€éŒ„"):
                st.session_state.total_count += 1
                if user_val == st.session_state['last_res']:
                    st.session_state.correct_count += 1
                    st.success("ç´€éŒ„æˆåŠŸï¼")
                else:
                    st.warning("å·²ç´€éŒ„éŒ¯èª¤ã€‚")
                del st.session_state['last_res'] # æ¸…é™¤æš«å­˜å¼·åˆ¶é‡æ•´
                st.rerun()

elif option == "ä½¿ç”¨ç›¸æ©Ÿæ‹ç…§" or option == "ä¸Šå‚³åœ–ç‰‡æª”":
    img_file = st.camera_input("ğŸ“¸ ç«‹å³æ‹æ”æ•¸å­—") if option == "ä½¿ç”¨ç›¸æ©Ÿæ‹ç…§" else st.file_uploader("ğŸ“ ä¸Šå‚³åœ–ç‰‡æª”æ¡ˆ", type=["jpg", "png", "jpeg"])
    
    if img_file:
        image = Image.open(img_file)
        img_array = np.array(image.convert('RGB'))
        img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        st.write("### ğŸ–¼ï¸ è™•ç†ç´°ç¯€ï¼š")
        st.image(image, width=400)
        
        res, confs, imgs = process_and_predict(img_gray)
        if res:
            st.divider()
            st.success(f"## ğŸ”¢ æœ€çµ‚è¾¨è­˜çµæœï¼š {''.join(map(str, res))}")
            cols = st.columns(min(len(imgs), 10))
            for i, im in enumerate(imgs):
                with cols[i]:
                    st.image(im, caption=f"é æ¸¬: {res[i]} ({confs[i]*100:.1f}%)")
        else:
            st.warning("åµæ¸¬ä¸åˆ°æ•¸å­—ï¼Œè«‹è©¦è‘—èª¿æ•´å´é¢æ¿åƒæ•¸ã€‚")