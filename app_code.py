import streamlit as st
import tensorflow as tf
import cv2
import numpy as np
from PIL import Image
from streamlit_drawable_canvas import st_canvas

# 1. é é¢è¨­å®šèˆ‡è¡Œå‹•ç«¯å„ªåŒ–
st.set_page_config(page_title="AIæ‰‹å¯«è¾¨è­˜APP", layout="wide")

# --- [æ–°å¢] CSS æ³¨å…¥ï¼šè§£æ±ºæ‰‹æ©Ÿ APP ä¸‹æ‹‰åˆ·æ–°å•é¡Œ ---
st.markdown(
    """
    <style>
    /* 1. ç¦æ­¢æ‰‹æ©Ÿç€è¦½å™¨ï¼ˆWebViewï¼‰åœ¨é ‚éƒ¨ä¸‹æ‹‰æ™‚é‡æ–°æ•´ç† */
    html, body, [data-testid="stAppViewContainer"] {
        overscroll-behavior-y: contain;
        overflow: hidden;
    }
    
    /* 2. è®“ç•«æ¿å€åŸŸå°ˆæ³¨æ–¼è§¸æ§æ›¸å¯«ï¼Œä¸è§¸ç™¼é é¢æ²å‹• */
    canvas {
        touch-action: none !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# --- æ¨™é¡Œèˆ‡ä¸‰é»æç¤º ---
st.title("ğŸ”¢ AIæ‰‹å¯«è¾¨è­˜APP")
st.markdown("""
##### ğŸ’¡ **ä½¿ç”¨èªªæ˜ï¼š**
1. **å¤šå…ƒè¼¸å…¥æ¨¡å¼**ï¼šæ”¯æ´ç•«æ¿æ‰‹å¯«ã€æ‹ç…§ã€åœ–ç‰‡æª”æ¡ˆä¸Šå‚³ã€‚
2. **æœ€ä½³è¾¨è­˜å»ºè­°**ï¼šå»ºè­°ä½¿ç”¨è¼ƒç²—çš„ç­†æ›¸å¯«ï¼ˆå¦‚é¦¬å…‹ç­†ï¼‰ï¼Œä¸¦åœ¨å…‰æºå……è¶³çš„æƒ…æ³ä¸‹æ‹æ”ï¼Œä»¥æé«˜è¾¨è­˜æˆåŠŸç‡ã€‚
3. **æ€§èƒ½å„ªåŒ–æ‰‹è…•**ï¼šè‹¥è¾¨è­˜ä¸ä½³ï¼Œå¯ä½¿ç”¨å´é¢æ¿å¾®èª¿åƒæ•¸æé«˜è¾¨è­˜æˆåŠŸç‡ã€‚
""")
st.divider()

# 2. è¼‰å…¥æ¨¡å‹ (ç¢ºä¿ mnist_model.h5 æª”æ¡ˆåœ¨åŒä¸€ç›®éŒ„ä¸‹)
@st.cache_resource
def load_my_model():
    # é€™è£¡å¯ä»¥æ ¹æ“šéœ€è¦æ”¹ç‚º load_model('mnist_model.h5')
    return tf.keras.models.load_model('mnist_model.h5')

try:
    model = load_my_model()
    st.sidebar.success("âœ… AI æ¨¡å‹å·²å°±ç·’")
except Exception as e:
    st.sidebar.error("âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨")

# 3. å´é‚Šæ¬„ï¼šåŠŸèƒ½è¨­å®šèˆ‡åƒæ•¸å¾®èª¿
st.sidebar.header("ğŸ› ï¸ ç³»çµ±åŠŸèƒ½è¨­å®š")
option = st.sidebar.radio("ğŸ“¸ é¸æ“‡è¼¸å…¥ä¾†æºï¼š", ("æ‰‹å¯«ç•«æ¿æ¨¡å¼", "ä½¿ç”¨ç›¸æ©Ÿæ‹ç…§", "ä¸Šå‚³åœ–ç‰‡æª”"))

st.sidebar.divider()
st.sidebar.write("ğŸ” è¾¨è­˜åƒæ•¸å¾®èª¿ (æ‹ç…§/ä¸Šå‚³å°ˆç”¨)")
min_area = st.sidebar.slider("1. é›œè¨Šéæ¿¾å¼·åº¦", 100, 1500, 300, help="æ•¸å€¼æ„ˆå¤§ï¼Œæ„ˆèƒ½éæ¿¾æ‰å¾®å°çš„é›œé»ã€‚")
sensitivity = st.sidebar.slider("2. æ•æ‰éˆæ•åº¦", 1, 25, 12, help="ç­†è·¡å¤ªæ·¡è«‹èª¿ä½ï¼Œé›œè¨Šå¤ªå¼·è«‹èª¿é«˜ã€‚")
thickness = st.sidebar.slider("3. å­—é«”åŠ ç²—ç¨‹åº¦", 1, 5, 2, help="é‡å°ç´°ç­†è·¡è£œå¼·ã€‚")

# 4. å½±åƒè™•ç†æ ¸å¿ƒå‡½æ•¸
def process_and_predict(img_gray, is_canvas=False):
    if is_canvas:
        # ç•«æ¿æ¨¡å¼ç›´æ¥äºŒå€¼åŒ–
        _, thresh = cv2.threshold(img_gray, 1, 255, cv2.THRESH_BINARY)
    else:
        # ç›¸æ©Ÿæ¨¡å¼éœ€å¼·åŒ–å°æ¯”èˆ‡é™å™ª
        enhanced = cv2.convertScaleAbs(img_gray, alpha=1.5, beta=0)
        blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)
        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                       cv2.THRESH_BINARY_INV, 11, sensitivity)
        kernel = np.ones((3,3), np.uint8)
        thresh = cv2.dilate(thresh, kernel, iterations=thickness)

    # å°‹æ‰¾è¼ªå»“
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    valid_contours = sorted([c for c in contours if cv2.contourArea(c) > min_area], 
                            key=lambda c: cv2.boundingRect(c)[0])
    
    if not contours or not valid_contours:
        return None, None

    results = []
    roi_images = []
    for cnt in valid_contours:
        x, y, w, h = cv2.boundingRect(cnt)
        pad = 20
        sq_size = max(w, h) + pad * 2
        roi = thresh[y:y+h, x:x+w]
        digit_canvas = np.zeros((sq_size, sq_size), dtype="uint8")
        digit_canvas[pad:pad+h, pad:pad+w] = roi
        final_img = cv2.resize(digit_canvas, (28, 28), interpolation=cv2.INTER_AREA)
        
        # æ¨¡å‹æ¨è«–
        input_data = final_img.astype('float32') / 255.0
        input_data = np.expand_dims(input_data, axis=(0, -1))
        prediction = model.predict(input_data, verbose=0)
        results.append(str(np.argmax(prediction)))
        roi_images.append(final_img)
        
    return results, roi_images

# 5. æ¨¡å¼åˆ‡æ›é‚è¼¯
if option == "æ‰‹å¯«ç•«æ¿æ¨¡å¼":
    st.write("### âœï¸ è«‹åœ¨é»‘è‰²ç•«æ¿å…§å¯«å…¥æ•¸å­—ï¼š")
    canvas_result = st_canvas(
        fill_color="rgba(255, 255, 255, 0.3)",
        stroke_width=20, # ç¨å¾®èª¿ç²—å¢åŠ æ‰‹æ©Ÿè¾¨è­˜åº¦
        stroke_color="#FFFFFF",
        background_color="#000000",
        width=700,
        height=300,
        drawing_mode="freedraw",
        key="canvas",
    )
    
    if canvas_result.image_data is not None:
        img_raw = canvas_result.image_data.astype('uint8')
        img_gray = cv2.cvtColor(img_raw, cv2.COLOR_RGBA2GRAY)
        
        if st.button("ğŸš€ é€²è¡Œ AI è¾¨è­˜"):
            res, imgs = process_and_predict(img_gray, is_canvas=True)
            if res:
                st.success(f"## æœ€çµ‚è¾¨è­˜çµæœï¼š {''.join(res)}")
                cols = st.columns(len(imgs))
                for i, im in enumerate(imgs):
                    cols[i].image(im, caption=f"é æ¸¬: {res[i]}")
            else:
                st.warning("è«‹åœ¨ç•«æ¿ä¸Šæ›¸å¯«æ•¸å­—å¾Œå†é€²è¡Œè¾¨è­˜ã€‚")

elif option == "ä½¿ç”¨ç›¸æ©Ÿæ‹ç…§" or option == "ä¸Šå‚³åœ–ç‰‡æª”":
    img_file = st.camera_input("ğŸ“¸ ç«‹å³æ‹æ”æ•¸å­—") if option == "ä½¿ç”¨ç›¸æ©Ÿæ‹ç…§" else st.file_uploader("ğŸ“ ä¸Šå‚³åœ–ç‰‡æª”æ¡ˆ", type=["jpg", "png", "jpeg"])
    
    if img_file:
        image = Image.open(img_file)
        img_array = np.array(image.convert('RGB'))
        img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        
        st.write("### ğŸ–¼ï¸ è™•ç†ç´°ç¯€ï¼š")
        st.image(image, width=400)
        
        res, imgs = process_and_predict(img_gray)
        if res:
            st.divider()
            st.success(f"## ğŸ”¢ æœ€çµ‚è¾¨è­˜çµæœï¼š {''.join(res)}")
            cols = st.columns(min(len(imgs), 10))
            for i, im in enumerate(imgs):
                with cols[i]:
                    st.image(im, caption=f"é æ¸¬: {res[i]}")
        else:
            st.warning("åµæ¸¬ä¸åˆ°æ•¸å­—ï¼Œè«‹è©¦è‘—èª¿æ•´å´é¢æ¿åƒæ•¸ã€‚")