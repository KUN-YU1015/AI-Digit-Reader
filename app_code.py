import streamlit as st
import tensorflow as tf
import cv2
import numpy as np
from PIL import Image

# 1. é é¢è¨­å®š
st.set_page_config(page_title="AIæ‰‹å¯«è¾¨è­˜APP", layout="wide")
# ä¿®æ”¹æ¨™é¡Œ
st.title("ğŸ”¢ AIæ‰‹å¯«è¾¨è­˜APP")
# å¢åŠ ä½¿ç”¨æç¤º
st.markdown("##### ğŸ’¡ **æç¤ºï¼šä½¿ç”¨è¼ƒç²—çš„ç­†æ›¸å¯«ï¼ˆå¦‚é¦¬å…‹ç­†ï¼‰ä¸¦åœ¨å…‰æºå……è¶³çš„æƒ…æ³ä¸‹æ‹æ”ç…§ç‰‡ï¼Œä»¥æé«˜è¾¨è­˜æˆåŠŸç‡ã€‚**")

# 2. è¼‰å…¥æ¨¡å‹
@st.cache_resource
def load_my_model():
    return tf.keras.models.load_model('mnist_model.h5')

try:
    model = load_my_model()
    st.success("âœ… AI è¾¨è­˜æ¨¡å‹å·²æˆåŠŸå•Ÿå‹•ï¼")
except Exception as e:
    st.error(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”ï¼Œè«‹ç¢ºä¿ 'mnist_model.h5' åœ¨åŒä¸€è³‡æ–™å¤¾ã€‚")

# 3. å´é‚Šæ¬„ï¼šäº’å‹•å¼æ€§èƒ½å„ªåŒ–
st.sidebar.header("ğŸ› ï¸ è¾¨è­˜æ€§èƒ½å„ªåŒ–")
sensitivity = st.sidebar.slider(
    "1. æ•æ‰éˆæ•åº¦", 1, 25, 12, 
    help="é‡å°ä¸åŒå…‰ç·šã€‚è‹¥ç­†è·¡å¤ªæ·¡ï¼Œè«‹ã€é™ä½ã€æ•¸å€¼ï¼›è‹¥é›œè¨Šéå¤šï¼Œè«‹ã€æé«˜ã€æ•¸å€¼ã€‚"
)
thickness = st.sidebar.slider(
    "2. å­—é«”åŠ ç²—ç¨‹åº¦", 1, 5, 2,
    help="é‡å°ç´°ç­†è·¡è£œå¼·ã€‚è‹¥æ•¸å­—æ–·è£‚ï¼Œè«‹ã€æé«˜ã€æ•¸å€¼ä»¥é€£æ¥ç­†åŠƒã€‚"
)
min_area = st.sidebar.slider(
    "3. é›œè¨Šéæ¿¾å¼·åº¦", 100, 1500, 300,
    help="å‰”é™¤å¾®å°é›œé»ã€‚è‹¥ç•«é¢å‡ºç¾éæ•¸å­—çš„å°ç¢æ¡†ï¼Œè«‹ã€æé«˜ã€æ•¸å€¼ã€‚"
)

st.sidebar.divider()
option = st.sidebar.radio("ğŸ“¸ é¸æ“‡è¼¸å…¥ä¾†æºï¼š", ("ä¸Šå‚³åœ–ç‰‡æª”", "ä½¿ç”¨ç›¸æ©Ÿæ‹ç…§"))

# 4. å½±åƒè¼¸å…¥èˆ‡è™•ç†
img_file = st.file_uploader("è«‹ä¸Šå‚³åœ–ç‰‡", type=["jpg", "png", "jpeg"]) if option == "ä¸Šå‚³åœ–ç‰‡æª”" else st.camera_input("æ‹ç…§")

if img_file is not None:
    image = Image.open(img_file)
    img_array = np.array(image.convert('RGB'))
    st.image(image, caption="åŸå§‹åœ–ç‰‡", width=400)

    # å½±åƒå¢å¼·è™•ç†
    gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    enhanced = cv2.convertScaleAbs(gray, alpha=3.0, beta=-150)
    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)
    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                   cv2.THRESH_BINARY_INV, 11, sensitivity)
    
    # å½¢æ…‹å­¸å„ªåŒ–
    kernel = np.ones((3,3), np.uint8)
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    thresh = cv2.dilate(thresh, kernel, iterations=thickness)
    
    # å°‹æ‰¾èˆ‡éæ¿¾è¼ªå»“
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    valid_contours = [c for c in contours if cv2.contourArea(c) > min_area]

    if valid_contours:
        # ç”±å·¦è‡³å³æ’åºè¼ªå»“
        valid_contours = sorted(valid_contours, key=lambda c: cv2.boundingRect(c)[0])
        
        st.write("### ğŸ¤– AI è¾¨è­˜ç´°ç¯€ (28x28 ç‰¹å¾µæå–)ï¼š")
        cols = st.columns(min(len(valid_contours), 10))
        results = []

        for i, cnt in enumerate(valid_contours):
            x, y, w, h = cv2.boundingRect(cnt)
            pad = 25
            sq_size = max(w, h) + pad * 2
            roi = thresh[y:y+h, x:x+w]
            digit_canvas = np.zeros((sq_size, sq_size), dtype="uint8")
            digit_canvas[pad:pad+h, pad:pad+w] = roi
            
            final_img = cv2.resize(digit_canvas, (28, 28), interpolation=cv2.INTER_AREA)
            input_data = final_img.astype('float32') / 255.0
            input_data = np.expand_dims(input_data, axis=(0, -1))
            
            prediction = model.predict(input_data, verbose=0)
            digit = np.argmax(prediction)
            results.append(str(digit))
            
            if i < 10:
                with cols[i]:
                    st.image(final_img, caption=f"é æ¸¬: {digit}")

        st.divider()
        st.success(f"## ğŸ”¢ æœ€çµ‚è¾¨è­˜çµæœï¼š {''.join(results)}")
    else:
        st.warning("åµæ¸¬ä¸åˆ°æ˜é¡¯æ•¸å­—ã€‚")